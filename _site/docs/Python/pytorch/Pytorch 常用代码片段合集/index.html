<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-2709176-10"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-2709176-10', { 'anonymize_ip': true }); </script> <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>PyTorch常用代码段 | Echo</title><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="PyTorch常用代码段" /><meta property="og:locale" content="en_US" /><meta name="description" content="A Jekyll theme for documentation" /><meta property="og:description" content="A Jekyll theme for documentation" /><link rel="canonical" href="http://localhost:4000/docs/Python/pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%90%88%E9%9B%86/" /><meta property="og:url" content="http://localhost:4000/docs/Python/pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%90%88%E9%9B%86/" /><meta property="og:site_name" content="Echo" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="PyTorch常用代码段" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"A Jekyll theme for documentation","headline":"PyTorch常用代码段","url":"http://localhost:4000/docs/Python/pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%90%88%E9%9B%86/"}</script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> Echo </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/tools" class="nav-list-link">Tools</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/tools/2022-06-18-SSH%20%E9%85%8D%E7%BD%AE%E5%85%AC%E9%92%A5%E7%99%BB%E5%BD%95/" class="nav-list-link">SSH 配置公钥登录</a><li class="nav-list-item "><a href="http://localhost:4000/docs/tools/2022-06-18-%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%8C%E9%87%8D%E8%AE%A4%E8%AF%81%E4%BB%A5%E5%8F%8A%E5%85%AC%E9%92%A5%E8%AE%A4%E8%AF%81%E7%99%BB%E5%BD%95/" class="nav-list-link">社交组服务器双重认证设置</a></ul><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/python" class="nav-list-link">Python</a><ul class="nav-list "><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Python/pandas/pandas/" class="nav-list-link">Pandas</a><ul class="nav-list"><li class="nav-list-item "> <a href="http://localhost:4000/docs/Python/pandas/2022-05-31-Pandas%E4%BB%8EPython%20dict%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/" class="nav-list-link">Pandas 从Python dict中加载数据</a></ul><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Python/Python%20codebase/python%20codebase/" class="nav-list-link">Python codebase</a><ul class="nav-list"><li class="nav-list-item "> <a href="http://localhost:4000/docs/Python/Python%20codebase/Python%20Google%20style%20comment/" class="nav-list-link">Python Google style comment</a><li class="nav-list-item "> <a href="http://localhost:4000/docs/Python/Python%20codebase/python%E5%A4%9A%E8%BF%9B%E7%A8%8B/" class="nav-list-link">Python 多进程</a></ul><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Python/pytorch/pytorch/" class="nav-list-link">Pytorch</a><ul class="nav-list"><li class="nav-list-item active"> <a href="http://localhost:4000/docs/Python/pytorch/Pytorch%20%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%90%88%E9%9B%86/" class="nav-list-link active">PyTorch常用代码段</a></ul></ul></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Echo" aria-label="Search Echo" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://github.com/ZipGao/" class="site-button" > GitHub </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/python">Python</a><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/Python/pytorch/pytorch/">Pytorch</a><li class="breadcrumb-nav-list-item"><span>PyTorch常用代码段</span></ol></nav><div id="main-content" class="main-content" role="main"><h1 id="深度学习框架pytorch常用代码段---知乎"> <a href="#深度学习框架pytorch常用代码段---知乎" class="anchor-heading" aria-labelledby="深度学习框架pytorch常用代码段---知乎"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> [深度学习框架]PyTorch常用代码段 - 知乎</h1><p>Created: May 30, 2022 3:38 PM</p><p>原文链接：<a href="https://zhuanlan.zhihu.com/p/104019160">[深度学习框架]PyTorch常用代码段-知乎</a></p><p>PyTorch最好的资料是<a href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/index.html">官方文档</a>。</p><p>本文是PyTorch常用代码段，在参考资料<a href="https://zhuanlan.zhihu.com/p/59205847">张皓：PyTorch Cookbook</a>的基础上做了一些修补，方便使用时查阅。</p><h2 id="1-基本配置"> <a href="#1-基本配置" class="anchor-heading" aria-labelledby="1-基本配置"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. 基本配置</h2><h3 id="导入包和版本查询"> <a href="#导入包和版本查询" class="anchor-heading" aria-labelledby="导入包和版本查询"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 导入包和版本查询</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">version</span><span class="p">.</span><span class="n">cuda</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">version</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div><h3 id="可复现性"> <a href="#可复现性" class="anchor-heading" aria-labelledby="可复现性"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 可复现性</h3><p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div><h3 id="显卡设置"> <a href="#显卡设置" class="anchor-heading" aria-labelledby="显卡设置"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 显卡设置</h3><p>如果只需要一张显卡</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Device configuration
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span><span class="p">)</span>
</code></pre></div></div><p>如果需要指定多张显卡，比如0，1号显卡。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'CUDA_VISIBLE_DEVICES'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'0,1'</span>
</code></pre></div></div><p>也可以在命令行运行代码时设置显卡：</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span> <span class="n">python</span> <span class="n">train</span><span class="p">.</span><span class="n">py</span>
</code></pre></div></div><p>清除显存</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span>
</code></pre></div></div><p>也可以使用在命令行重置GPU的指令</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span> <span class="o">--</span><span class="n">gpu</span><span class="o">-</span><span class="n">reset</span> <span class="o">-</span><span class="n">i</span> <span class="p">[</span><span class="n">gpu_id</span><span class="p">]</span>
</code></pre></div></div><h2 id="2-张量tensor处理"> <a href="#2-张量tensor处理" class="anchor-heading" aria-labelledby="2-张量tensor处理"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. 张量(Tensor)处理</h2><h3 id="张量的数据类型"> <a href="#张量的数据类型" class="anchor-heading" aria-labelledby="张量的数据类型"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 张量的数据类型</h3><p>PyTorch有9种CPU张量类型和9种GPU张量类型。</p><h3 id="张量基本信息"> <a href="#张量基本信息" class="anchor-heading" aria-labelledby="张量基本信息"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 张量基本信息</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="nb">type</span><span class="p">())</span> <span class="err"> </span><span class="c1"># 数据类型
</span><span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="err"> </span><span class="c1"># 张量的shape，是个元组
</span><span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">dim</span><span class="p">())</span> <span class="err"> </span> <span class="c1"># 维度的数量
</span></code></pre></div></div><h3 id="命名张量"> <a href="#命名张量" class="anchor-heading" aria-labelledby="命名张量"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 命名张量</h3><p>张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性、易用性，防止出错。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 在PyTorch 1.3之前，需要使用注释
# Tensor[N, C, H, W]
</span><span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">)</span>
<span class="n">images</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">images</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># PyTorch 1.3之后
</span><span class="n">NCHW</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">N</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="n">C</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="n">H</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="n">W</span><span class="err">’</span><span class="p">]</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">NCHW</span><span class="p">)</span>
<span class="n">images</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="s">'C'</span><span class="p">)</span>
<span class="n">images</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'C'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># 也可以这么设置
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="p">(</span><span class="s">'C'</span><span class="p">,</span> <span class="s">'N'</span><span class="p">,</span> <span class="s">'H'</span><span class="p">,</span> <span class="s">'W'</span><span class="p">))</span>
<span class="c1"># 使用align_to可以对维度方便地排序
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">align_to</span><span class="p">(</span><span class="s">'N'</span><span class="p">,</span> <span class="s">'C'</span><span class="p">,</span> <span class="s">'H'</span><span class="p">,</span> <span class="s">'W'</span><span class="p">)</span>
</code></pre></div></div><h3 id="数据类型转换"> <a href="#数据类型转换" class="anchor-heading" aria-labelledby="数据类型转换"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 数据类型转换</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor
</span><span class="n">torch</span><span class="p">.</span><span class="n">set_default_tensor_type</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">)</span>
<span class="c1"># 类型转换
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nb">float</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nb">long</span><span class="p">()</span>
</code></pre></div></div><h3 id="torchtensor与npndarray转换"> <a href="#torchtensor与npndarray转换" class="anchor-heading" aria-labelledby="torchtensor与npndarray转换"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>torch.Tensor与np.ndarray转换</strong></h3><p>除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ndarray</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ndarray</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ndarray</span><span class="p">.</span><span class="n">copy</span><span class="p">()).</span><span class="nb">float</span><span class="p">()</span> <span class="c1"># If ndarray has negative stride.
</span></code></pre></div></div><h3 id="torchtensor与pilimage转换"> <a href="#torchtensor与pilimage转换" class="anchor-heading" aria-labelledby="torchtensor与pilimage转换"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Torch.tensor与PIL.Image转换</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化
# torch.Tensor -&gt; PIL.Image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">PIL</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">tensor</span><span class="o">*</span><span class="mi">255</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">255</span><span class="p">).</span><span class="n">byte</span><span class="p">().</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">to_pil_image</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="err"> </span><span class="c1"># Equivalently way
# PIL.Image -&gt; torch.Tensor
</span><span class="n">path</span> <span class="o">=</span> <span class="sa">r</span><span class="s">'./figure.jpg'</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">PIL</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">))).</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">PIL</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">))</span> <span class="c1"># Equivalently way
</span></code></pre></div></div><h3 id="npndarray与pilimage的转换"> <a href="#npndarray与pilimage的转换" class="anchor-heading" aria-labelledby="npndarray与pilimage的转换"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>np.ndarray与PIL.Image的转换</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">PIL</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">ndarray</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">))</span>
<span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">PIL</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
</code></pre></div></div><h3 id="从只包含一个元素的张量中提取值"> <a href="#从只包含一个元素的张量中提取值" class="anchor-heading" aria-labelledby="从只包含一个元素的张量中提取值"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>从只包含一个元素的张量中提取值</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div><h3 id="张量形变"> <a href="#张量形变" class="anchor-heading" aria-labelledby="张量形变"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>张量形变</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，
# 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</code></pre></div></div><h3 id="打乱顺序"> <a href="#打乱顺序" class="anchor-heading" aria-labelledby="打乱顺序"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>打乱顺序</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))]</span> <span class="err"> </span><span class="c1"># 打乱第一个维度
</span></code></pre></div></div><h3 id="水平翻转"> <a href="#水平翻转" class="anchor-heading" aria-labelledby="水平翻转"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>水平翻转</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现
# 假设张量的维度为[N, D, H, W].
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,:,:,</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nb">long</span><span class="p">()]</span>
</code></pre></div></div><h3 id="复制张量"> <a href="#复制张量" class="anchor-heading" aria-labelledby="复制张量"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>复制张量</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Operation                 |  New/Shared memory | Still in computation graph |
</span><span class="n">tensor</span><span class="p">.</span><span class="n">clone</span><span class="p">()</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="c1"># |        New         |          Yes               |
</span><span class="n">tensor</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># |      Shared        |          No                |
</span><span class="n">tensor</span><span class="p">.</span><span class="n">detach</span><span class="p">.</span><span class="n">clone</span><span class="p">()()</span> <span class="err"> </span> <span class="c1"># |        New         |          No                |
</span></code></pre></div></div><h3 id="张量拼接"> <a href="#张量拼接" class="anchor-heading" aria-labelledby="张量拼接"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>张量拼接</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">'''
注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，
而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，
而torch.stack的结果是3x10x5的张量。
'''</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">list_of_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">list_of_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><h3 id="将整数标签转为one-hot编码"> <a href="#将整数标签转为one-hot编码" class="anchor-heading" aria-labelledby="将整数标签转为one-hot编码"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>将整数标签转为one-hot编码</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pytorch的标记默认从0开始
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
<span class="n">one_hot</span><span class="p">.</span><span class="n">scatter_</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">src</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">).</span><span class="nb">long</span><span class="p">())</span>
</code></pre></div></div><h3 id="得到非零元素"> <a href="#得到非零元素" class="anchor-heading" aria-labelledby="得到非零元素"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>得到非零元素</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># index of non-zero elements
</span><span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">tensor</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="c1"># index of zero elements
</span><span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">tensor</span><span class="p">).</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># number of non-zero elements
</span><span class="n">torch</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">tensor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">).</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="err"> </span><span class="c1"># number of zero elements
</span></code></pre></div></div><h3 id="判断两个张量相等"> <a href="#判断两个张量相等" class="anchor-heading" aria-labelledby="判断两个张量相等"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>判断两个张量相等</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span> <span class="err"> </span><span class="c1"># float tensor
</span><span class="n">torch</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># int tensor
</span></code></pre></div></div><h3 id="张量扩展"> <a href="#张量扩展" class="anchor-heading" aria-labelledby="张量扩展"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>张量扩展</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Expand tensor of shape 64*512 to shape 64*512*7*7.
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">512</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="n">expand</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</code></pre></div></div><h3 id="矩阵乘法"> <a href="#矩阵乘法" class="anchor-heading" aria-labelledby="矩阵乘法"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>矩阵乘法</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Matrix multiplcation: (m*n) * (n*p) * -&gt; (m*p).
</span><span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mm</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span>
<span class="c1"># Batch matrix multiplication: (b*m*n) * (b*n*p) -&gt; (b*m*p)
</span><span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span>
<span class="c1"># Element-wise multiplication.
</span><span class="n">result</span> <span class="o">=</span> <span class="n">tensor1</span> <span class="o">*</span> <span class="n">tensor2</span>
</code></pre></div></div><h3 id="计算两组数据之间的两两欧式距离"> <a href="#计算两组数据之间的两两欧式距离" class="anchor-heading" aria-labelledby="计算两组数据之间的两两欧式距离"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>计算两组数据之间的两两欧式距离</strong></h3><p>利用broadcast机制</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">X1</span><span class="p">[:,</span><span class="bp">None</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">X2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div><h2 id="3-模型定义和操作"> <a href="#3-模型定义和操作" class="anchor-heading" aria-labelledby="3-模型定义和操作"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. 模型定义和操作</h2><h3 id="一个简单两层卷积网络的示例"> <a href="#一个简单两层卷积网络的示例" class="anchor-heading" aria-labelledby="一个简单两层卷积网络的示例"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 一个简单两层卷积网络的示例</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convolutional neural network (2 convolutional layers)
</span><span class="k">class</span> <span class="nc">ConvNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nb">super</span><span class="p">(</span><span class="n">ConvNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">out</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNet</span><span class="p">(</span><span class="n">num_classes</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div><p>卷积层的计算和展示可以用<a href="https://link.zhihu.com/?target=https%3A//ezyang.github.io/convolution-visualizer/index.html">这个网站</a>辅助。</p><h3 id="双线性汇合bilinear-pooling"> <a href="#双线性汇合bilinear-pooling" class="anchor-heading" aria-labelledby="双线性汇合bilinear-pooling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>双线性汇合（bilinear pooling）</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="c1"># Assume X has shape N*D*H*W
</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span> <span class="err"> </span><span class="c1"># Bilinear pooling
</span><span class="k">assert</span> <span class="n">X</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">*</span> <span class="n">D</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sign</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span> <span class="err"> </span> <span class="c1"># Signed-sqrt normalization
</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="c1"># L2 normalization
</span></code></pre></div></div><h3 id="多卡同步-bnbatch-normalization"> <a href="#多卡同步-bnbatch-normalization" class="anchor-heading" aria-labelledby="多卡同步-bnbatch-normalization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>多卡同步 BN（Batch normalization）</strong></h3><p>当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sync_bn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">SyncBatchNorm</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div><h3 id="将已有网络的所有bn层改为同步bn层"> <a href="#将已有网络的所有bn层改为同步bn层" class="anchor-heading" aria-labelledby="将已有网络的所有bn层改为同步bn层"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 将已有网络的所有BN层改为同步BN层</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">convertBNtoSyncBN</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">process_group</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="s">'''Recursively replace all BN layers to SyncBN layer.
    Args:
        module[torch.nn.Module]. Network
    '''</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">modules</span><span class="p">.</span><span class="n">batchnorm</span><span class="p">.</span><span class="n">_BatchNorm</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">sync_bn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">SyncBatchNorm</span><span class="p">(</span><span class="n">module</span><span class="p">.</span><span class="n">num_features</span><span class="p">,</span> <span class="n">module</span><span class="p">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">module</span><span class="p">.</span><span class="n">momentum</span><span class="p">,</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="n">module</span><span class="p">.</span><span class="n">affine</span><span class="p">,</span> <span class="n">module</span><span class="p">.</span><span class="n">track_running_stats</span><span class="p">,</span> <span class="n">process_group</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">sync_bn</span><span class="p">.</span><span class="n">running_mean</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">running_mean</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">sync_bn</span><span class="p">.</span><span class="n">running_var</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">running_var</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">module</span><span class="p">.</span><span class="n">affine</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">sync_bn</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">clone</span><span class="p">().</span><span class="n">detach</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">sync_bn</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">clone</span><span class="p">().</span><span class="n">detach</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">sync_bn</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">child_module</span> <span class="ow">in</span> <span class="n">module</span><span class="p">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="o">=</span> <span class="n">convert_syncbn_model</span><span class="p">(</span><span class="n">child_module</span><span class="p">,</span> <span class="n">process_group</span><span class="o">=</span><span class="n">process_group</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">module</span>
</code></pre></div></div><h3 id="类似-bn-滑动平均"> <a href="#类似-bn-滑动平均" class="anchor-heading" aria-labelledby="类似-bn-滑动平均"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>类似 BN 滑动平均</strong></h3><p>如果要实现类似 BN 滑动平均的操作，在 forward 函数中要使用原地（inplace）操作给滑动平均赋值。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">...</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">'running_mean'</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">...</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">running_mean</span> <span class="o">+=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="p">(</span><span class="n">current</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">running_mean</span><span class="p">)</span>
</code></pre></div></div><h3 id="计算模型整体参数量"> <a href="#计算模型整体参数量" class="anchor-heading" aria-labelledby="计算模型整体参数量"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>计算模型整体参数量</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_parameters</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">numel</span><span class="p">(</span><span class="n">parameter</span><span class="p">)</span> <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span>
</code></pre></div></div><h3 id="查看网络中的参数"> <a href="#查看网络中的参数" class="anchor-heading" aria-labelledby="查看网络中的参数"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>查看网络中的参数</strong></h3><p>可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">named_parameters</span><span class="p">())</span>
<span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">28</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">param</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-------------------------------------------------'</span><span class="p">)</span>
<span class="p">(</span><span class="n">name2</span><span class="p">,</span> <span class="n">param2</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">29</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">name2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">param2</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'----------------------------------------------------'</span><span class="p">)</span>
<span class="p">(</span><span class="n">name1</span><span class="p">,</span> <span class="n">param1</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">30</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">name1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">param1</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div></div><h3 id="模型可视化使用pytorchviz"> <a href="#模型可视化使用pytorchviz" class="anchor-heading" aria-labelledby="模型可视化使用pytorchviz"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型可视化（使用pytorchviz）</h3><h3 id="类似-keras-的-modelsummary-输出模型信息使用pytorch-summary-"> <a href="#类似-keras-的-modelsummary-输出模型信息使用pytorch-summary-" class="anchor-heading" aria-labelledby="类似-keras-的-modelsummary-输出模型信息使用pytorch-summary-"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>类似 Keras 的 model.summary() 输出模型信息（</strong>使用pytorch-summary <strong>）</strong></h3><p><strong>模型权重初始化</strong> 注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Common practise for initialization.
</span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">modules</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'fan_out'</span><span class="p">,</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">layer</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">layer</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="c1"># Initialization with given tensor.
</span><span class="n">layer</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</code></pre></div></div><h3 id="提取模型中的某一层"> <a href="#提取模型中的某一层" class="anchor-heading" aria-labelledby="提取模型中的某一层"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>提取模型中的某一层</strong></h3><p>modules()会返回模型中所有模块的迭代器，它能够访问到最内层，比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 取模型中的前两层
</span><span class="n">new_model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">children</span><span class="p">())[:</span><span class="mi">2</span><span class="p">]</span>
<span class="c1"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：
</span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">named_modules</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="n">conv_model</span><span class="p">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></div><h3 id="部分层使用预训练模型"> <a href="#部分层使用预训练模型" class="anchor-heading" aria-labelledby="部分层使用预训练模型"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>部分层使用预训练模型</strong></h3><p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'model.pth'</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div><h3 id="将在-gpu-保存的模型加载到-cpu"> <a href="#将在-gpu-保存的模型加载到-cpu" class="anchor-heading" aria-labelledby="将在-gpu-保存的模型加载到-cpu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>将在 GPU 保存的模型加载到 CPU</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'model.pth'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s">'cpu'</span><span class="p">))</span>
</code></pre></div></div><h2 id="导入另一个模型的相同部分到新的模型"> <a href="#导入另一个模型的相同部分到新的模型" class="anchor-heading" aria-labelledby="导入另一个模型的相同部分到新的模型"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 导入另一个模型的相同部分到新的模型</h2><p>模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># model_new代表新的模型
# model_saved代表其他模型，比如用torch.load导入的已保存的模型
</span><span class="n">model_new_dict</span> <span class="o">=</span> <span class="n">model_new</span><span class="p">.</span><span class="n">state_dict</span><span class="p">()</span>
<span class="n">model_common_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model_saved</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">model_new_dict</span><span class="p">.</span><span class="n">keys</span><span class="p">()}</span>
<span class="n">model_new_dict</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">model_common_dict</span><span class="p">)</span>
<span class="n">model_new</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_new_dict</span><span class="p">)</span>
</code></pre></div></div><h2 id="4-数据处理"> <a href="#4-数据处理" class="anchor-heading" aria-labelledby="4-数据处理"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>4. 数据处理</strong></h2><h3 id="计算数据集的均值和标准差"> <a href="#计算数据集的均值和标准差" class="anchor-heading" aria-labelledby="计算数据集的均值和标准差"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>计算数据集的均值和标准差</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="k">def</span> <span class="nf">compute_mean_and_std</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># 输入PyTorch的dataset，输出均值和标准差
</span><span class="err"> </span> <span class="err"> </span> <span class="n">mean_r</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mean_g</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mean_b</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="c1"># change PIL Image to numpy array
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">mean_r</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">mean_g</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">mean_b</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mean_r</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mean_g</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mean_b</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">diff_r</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">diff_g</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">diff_b</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">N</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">diff_r</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_r</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">diff_g</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_g</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">diff_b</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_b</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">N</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">std_r</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_r</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">std_g</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_g</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">std_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">diff_b</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean_r</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">mean_g</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">std</span> <span class="o">=</span> <span class="p">(</span><span class="n">std_r</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">std_g</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">std_b</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
</code></pre></div></div><h3 id="得到视频数据基本信息"> <a href="#得到视频数据基本信息" class="anchor-heading" aria-labelledby="得到视频数据基本信息"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>得到视频数据基本信息</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">mp4_path</span><span class="p">)</span>
<span class="n">height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">video</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">))</span>
<span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">video</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">))</span>
<span class="n">num_frames</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">video</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FRAME_COUNT</span><span class="p">))</span>
<span class="n">fps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">video</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FPS</span><span class="p">))</span>
<span class="n">video</span><span class="p">.</span><span class="n">release</span><span class="p">()</span>
</code></pre></div></div><h3 id="tsn-每段segment采样一帧视频"> <a href="#tsn-每段segment采样一帧视频" class="anchor-heading" aria-labelledby="tsn-每段segment采样一帧视频"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>TSN 每段（segment）采样一帧视频</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_num_segments</span>
<span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">num_frames</span> <span class="o">&gt;</span> <span class="n">K</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># Random index for each segment.
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">high</span><span class="o">=</span><span class="n">num_frames</span> <span class="o">//</span> <span class="n">K</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">+=</span> <span class="n">num_frames</span> <span class="o">//</span> <span class="n">K</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">high</span><span class="o">=</span><span class="n">num_frames</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">K</span> <span class="o">-</span> <span class="n">num_frames</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_frames</span><span class="p">),</span> <span class="n">frame_indices</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">num_frames</span> <span class="o">&gt;</span> <span class="n">K</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># Middle index for each segment.
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">=</span> <span class="n">num_frames</span> <span class="o">/</span> <span class="n">K</span> <span class="o">//</span> <span class="mi">2</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">+=</span> <span class="n">num_frames</span> <span class="o">//</span> <span class="n">K</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">frame_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_frames</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span> <span class="o">-</span> <span class="n">num_frames</span><span class="p">))))[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">frame_indices</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="p">(</span><span class="n">K</span><span class="p">,)</span>
<span class="k">return</span> <span class="p">[</span><span class="n">frame_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span>
</code></pre></div></div><h3 id="常用训练和验证数据预处理"> <a href="#常用训练和验证数据预处理" class="anchor-heading" aria-labelledby="常用训练和验证数据预处理"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>常用训练和验证数据预处理</strong></h3><p>其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的 torch.Tensor。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)),</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)),</span>
<span class="err"> </span><span class="p">])</span>
<span class="err"> </span><span class="n">val_transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span><span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)),</span>
<span class="p">])</span>
</code></pre></div></div><h2 id="5-模型训练和测试"> <a href="#5-模型训练和测试" class="anchor-heading" aria-labelledby="5-模型训练和测试"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5. 模型训练和测试</h2><h3 id="分类模型训练代码"> <a href="#分类模型训练代码" class="anchor-heading" aria-labelledby="分类模型训练代码"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 分类模型训练代码</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loss and optimizer
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="c1"># Train the model
</span><span class="n">total_step</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">i</span> <span class="p">,(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># Forward pass
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># Backward and optimizer
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">print</span><span class="p">(</span><span class="s">'Epoch: [{}/{}], Step: [{}/{}], Loss: {}'</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_step</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()))</span>
</code></pre></div></div><h3 id="分类模型测试代码"> <a href="#分类模型测试代码" class="anchor-heading" aria-labelledby="分类模型测试代码"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 分类模型测试代码</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Test the model
</span><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span> <span class="err"> </span><span class="c1"># eval mode(batch norm uses moving mean/variance
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1">#instead of mini-batch mean/variance)
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">print</span><span class="p">(</span><span class="s">'Test accuracy of the model on the 10000 test images: {} %'</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">))</span>
</code></pre></div></div><h3 id="自定义loss"> <a href="#自定义loss" class="anchor-heading" aria-labelledby="自定义loss"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 自定义loss</h3><p>继承torch.nn.Module类写自己的loss。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyLoss</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Moudle</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nb">super</span><span class="p">(</span><span class="n">MyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div><h3 id="标签平滑label-smoothing"> <a href="#标签平滑label-smoothing" class="anchor-heading" aria-labelledby="标签平滑label-smoothing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>标签平滑（label smoothing）</strong></h3><p>写一个label_smoothing.py的文件，然后在训练代码里引用，用LSR代替交叉熵损失即可。label_smoothing.py内容如下：</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="k">class</span> <span class="nc">LSR</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">e</span> <span class="o">=</span> <span class="n">e</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">reduction</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="s">"""
            Convert labels to one hot vectors
        Args:
            labels: torch tensor in format [label1, label2, label3, ...]
            classes: int, number of classes
            value: label value in one hot vector, default to 1
        Returns:
            return one hot format labels in shape [batchsize, classes]
        """</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">classes</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1">#labels and value_added  size must match
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">value_added</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">).</span><span class="n">fill_</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">value_added</span> <span class="o">=</span> <span class="n">value_added</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">labels</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">one_hot</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">labels</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">one_hot</span><span class="p">.</span><span class="n">scatter_add_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">value_added</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">one_hot</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">_smooth_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="s">"""convert targets to one-hot format, and smooth
        them.
        Args:
            target: target in form with [label1, label2, label_batchsize]
            length: length of one-hot format(number of classes)
            smooth_factor: smooth factor for label smooth
        Returns:
            smoothed labels in one hot format
        """</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_one_hot</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">smooth_factor</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">one_hot</span> <span class="o">+=</span> <span class="n">smooth_factor</span> <span class="o">/</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">one_hot</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">!=</span> <span class="n">target</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">'Expected input batchsize ({}) to match target batch_size({})'</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">target</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">'Expected input tensor to have least 2 dimensions(got {})'</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">'Only 2 dimension tensor are implemented, (got {})'</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">()))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">smoothed_target</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_smooth_label</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">e</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="o">-</span> <span class="n">x</span> <span class="o">*</span> <span class="n">smoothed_target</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s">'none'</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">loss</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s">'sum'</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s">'mean'</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">'unrecognized option, expect reduction to be one of none, mean, sum'</span><span class="p">)</span>
</code></pre></div></div><p>或者直接在训练文件里做label smoothing</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">labels</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">N</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># C is the number of classes.
</span><span class="err"> </span> <span class="err"> </span> <span class="n">smoothed_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">full</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">/</span> <span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">smoothed_labels</span><span class="p">.</span><span class="n">scatter_</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">log_prob</span> <span class="o">*</span> <span class="n">smoothed_labels</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div><h3 id="mixup训练"> <a href="#mixup训练" class="anchor-heading" aria-labelledby="mixup训练"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Mixup训练</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">beta_distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="n">beta</span><span class="p">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">labels</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Mixup images and labels.
</span><span class="err"> </span> <span class="err"> </span> <span class="n">lambda_</span> <span class="o">=</span> <span class="n">beta_distribution</span><span class="p">.</span><span class="n">sample</span><span class="p">([]).</span><span class="n">item</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mixed_images</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">images</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lambda_</span><span class="p">)</span> <span class="o">*</span> <span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">label_a</span><span class="p">,</span> <span class="n">label_b</span> <span class="o">=</span> <span class="n">labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Mixup loss.
</span><span class="err"> </span> <span class="err"> </span> <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mixed_images</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_</span> <span class="o">*</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">label_a</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lambda_</span><span class="p">)</span> <span class="o">*</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">label_b</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div><h3 id="l1-正则化"> <a href="#l1-正则化" class="anchor-heading" aria-labelledby="l1-正则化"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>L1 正则化</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">l1_regularization</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="p">...</span> <span class="err"> </span><span class="c1"># Standard cross-entropy loss
</span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">loss</span> <span class="o">+=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></div><h3 id="不对偏置项进行权重衰减weight-decay"> <a href="#不对偏置项进行权重衰减weight-decay" class="anchor-heading" aria-labelledby="不对偏置项进行权重衰减weight-decay"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>不对偏置项进行权重衰减（weight decay）</strong></h3><p>pytorch里的weight decay相当于l2正则</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bias_list</span> <span class="o">=</span> <span class="p">(</span><span class="n">param</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span> <span class="o">==</span> <span class="s">'bias'</span><span class="p">)</span>
<span class="n">others_list</span> <span class="o">=</span> <span class="p">(</span><span class="n">param</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span> <span class="o">!=</span> <span class="s">'bias'</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">[{</span><span class="s">'parameters'</span><span class="p">:</span> <span class="n">bias_list</span><span class="p">,</span> <span class="s">'weight_decay'</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">{</span><span class="s">'parameters'</span><span class="p">:</span> <span class="n">others_list</span><span class="p">}]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</code></pre></div></div><h3 id="梯度裁剪gradient-clipping"> <a href="#梯度裁剪gradient-clipping" class="anchor-heading" aria-labelledby="梯度裁剪gradient-clipping"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>梯度裁剪（gradient clipping）</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</code></pre></div></div><h3 id="得到当前学习率"> <a href="#得到当前学习率" class="anchor-heading" aria-labelledby="得到当前学习率"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>得到当前学习率</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If there is one global learning rate (which is the common case).
</span><span class="n">lr</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">optimizer</span><span class="p">.</span><span class="n">param_groups</span><span class="p">))[</span><span class="s">'lr'</span><span class="p">]</span>
<span class="c1"># If there are multiple learning rates for different layers.
</span><span class="n">all_lr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">param_groups</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">all_lr</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_group</span><span class="p">[</span><span class="s">'lr'</span><span class="p">])</span>
</code></pre></div></div><p>另一种方法，在一个batch训练代码里，当前的lr是optimizer.param_groups[0][‘lr’]</p><h3 id="学习率衰减"> <a href="#学习率衰减" class="anchor-heading" aria-labelledby="学习率衰减"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>学习率衰减</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Reduce learning rate when validation accuarcy plateau.
</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'max'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">train</span><span class="p">(...)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">val</span><span class="p">(...)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>
<span class="c1"># Cosine annealing learning rate.
</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="c1"># Reduce learning rate by 10 at given epochs.
</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">MultiStepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">train</span><span class="p">(...)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">val</span><span class="p">(...)</span>
<span class="c1"># Learning rate warmup by 10 epochs.
</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">train</span><span class="p">(...)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">val</span><span class="p">(...)</span>
</code></pre></div></div><h3 id="优化器链式更新"> <a href="#优化器链式更新" class="anchor-heading" aria-labelledby="优化器链式更新"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 优化器链式更新</h3><p>从1.4版本开始，torch.optim.lr_scheduler 支持链式更新（chaining），即用户可以定义两个 schedulers，并交替在训练中使用。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span>
<span class="n">model</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">))]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">scheduler1</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">scheduler2</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div><h3 id="模型训练可视化"> <a href="#模型训练可视化" class="anchor-heading" aria-labelledby="模型训练可视化"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型训练可视化</h3><p>PyTorch可以使用tensorboard来可视化训练过程。 安装和运行TensorBoard。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">tensorboard</span>
<span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=</span><span class="n">runs</span>
</code></pre></div></div><p>使用SummaryWriter类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如’Loss/train’和’Loss/test’。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'Loss/train'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'Loss/test'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'Accuracy/train'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'Accuracy/test'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
</code></pre></div></div><h3 id="保存与加载断点"> <a href="#保存与加载断点" class="anchor-heading" aria-labelledby="保存与加载断点"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>保存与加载断点</strong></h3><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># Load checkpoint.
</span><span class="k">if</span> <span class="n">resume</span><span class="p">:</span> <span class="c1"># resume为参数，第一次训练时设为0，中断再训练时设为1
</span><span class="err"> </span> <span class="err"> </span> <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="s">'best_checkpoint.pth.tar'</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">assert</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">best_acc</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">'best_acc'</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">'epoch'</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s">'model'</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">optimizer</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s">'optimizer'</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">print</span><span class="p">(</span><span class="s">'Load checkpoint at epoch {}.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">print</span><span class="p">(</span><span class="s">'Best accuracy so far {}.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">best_acc</span><span class="p">))</span>
<span class="c1"># Train the model
</span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="p">...</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Test the model
</span><span class="err"> </span> <span class="err"> </span> <span class="p">...</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># save checkpoint
</span><span class="err"> </span> <span class="err"> </span> <span class="n">is_best</span> <span class="o">=</span> <span class="n">current_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">best_acc</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">current_acc</span><span class="p">,</span> <span class="n">best_acc</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="s">'best_acc'</span><span class="p">:</span> <span class="n">best_acc</span><span class="p">,</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="s">'epoch'</span><span class="p">:</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="s">'model'</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="s">'optimizer'</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span>
<span class="err"> </span> <span class="err"> </span> <span class="p">}</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="s">'checkpoint.pth.tar'</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">best_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="s">'best_checkpoint.pth.tar'</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">shutil</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">best_model_path</span><span class="p">)</span>
</code></pre></div></div><h3 id="提取-imagenet-预训练模型某层的卷积特征"> <a href="#提取-imagenet-预训练模型某层的卷积特征" class="anchor-heading" aria-labelledby="提取-imagenet-预训练模型某层的卷积特征"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>提取 ImageNet 预训练模型某层的卷积特征</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># VGG-16 relu5-3 feature.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># VGG-16 pool5 feature.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">features</span>
<span class="c1"># VGG-16 fc7 feature.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">classifier</span><span class="p">.</span><span class="n">children</span><span class="p">())[:</span><span class="o">-</span><span class="mi">3</span><span class="p">])</span>
<span class="c1"># ResNet GAP feature.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">collections</span><span class="p">.</span><span class="n">OrderedDict</span><span class="p">(</span>
<span class="err"> </span> <span class="err"> </span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">named_children</span><span class="p">())[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">conv_representation</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div></div><h3 id="提取-imagenet-预训练模型多层的卷积特征"> <a href="#提取-imagenet-预训练模型多层的卷积特征" class="anchor-heading" aria-labelledby="提取-imagenet-预训练模型多层的卷积特征"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>提取 ImageNet 预训练模型多层的卷积特征</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">FeatureExtractor</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="s">"""Helper class to extract several convolution features from the given
    pre-trained model.
    Attributes:
        _model, torch.nn.Module.
        _layers_to_extract, list&lt;str&gt; or set&lt;str&gt;
    Example:
        &gt;&gt;&gt; model = torchvision.models.resnet152(pretrained=True)
        &gt;&gt;&gt; model = torch.nn.Sequential(collections.OrderedDict(
                list(model.named_children())[:-1]))
        &gt;&gt;&gt; conv_representation = FeatureExtractor(
                pretrained_model=model,
                layers_to_extract={'layer1', 'layer2', 'layer3', 'layer4'})(image)
    """</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">layers_to_extract</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">pretrained_model</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">_model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="bp">self</span><span class="p">.</span><span class="n">_layers_to_extract</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">layers_to_extract</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">conv_representation</span> <span class="o">=</span> <span class="p">[]</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_model</span><span class="p">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_layers_to_extract</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">conv_representation</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">conv_representation</span>
</code></pre></div></div><h3 id="微调全连接层"> <a href="#微调全连接层" class="anchor-heading" aria-labelledby="微调全连接层"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>微调全连接层</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">model</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="err"> </span><span class="c1"># Replace the last fc layer
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</code></pre></div></div><h3 id="以较大学习率微调全连接层较小学习率微调卷积层"> <a href="#以较大学习率微调全连接层较小学习率微调卷积层" class="anchor-heading" aria-labelledby="以较大学习率微调全连接层较小学习率微调卷积层"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>以较大学习率微调全连接层，较小学习率微调卷积层</strong></h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">finetuned_parameters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">parameters</span><span class="p">()))</span>
<span class="n">conv_parameters</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">finetuned_parameters</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">[{</span><span class="s">'params'</span><span class="p">:</span> <span class="n">conv_parameters</span><span class="p">,</span> <span class="s">'lr'</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">},</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="p">{</span><span class="s">'params'</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">parameters</span><span class="p">()}]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</code></pre></div></div><h2 id="6-其他注意事项"> <a href="#6-其他注意事项" class="anchor-heading" aria-labelledby="6-其他注意事项"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 6. 其他注意事项</h2><ul><li>不要使用太大的线性层。因为nn.Linear(m,n)使用的是 的内存，线性层太大很容易超出现有显存。<li>不要在太长的序列上使用RNN。因为RNN反向传播使用的是BPTT算法，其需要的内存和输入序列的长度呈线性关系。<li>model(x) 前用 model.train() 和 model.eval() 切换网络状态。<li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。<li>model.eval() 和 torch.no_grad() 的区别在于，model.eval() 是将网络切换为测试状态，例如 BN 和dropout在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 loss.backward()。<li>model.zero_grad()会把整个模型的参数的梯度都归零, 而optimizer.zero_grad()只会把传入其中的参数的梯度归零.<li>torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。<li>loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。<li>torch.utils.data.DataLoader 中尽量设置 pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False 反而更快一些。num_workers 的设置需要在实验中找到最快的取值。<li>用 del 及时删除不用的中间变量，节约 GPU 存储。<li>使用 inplace 操作可节约 GPU 存储，如<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div><li>减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。<li>使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。<li>时常使用 assert tensor.size() == (N, D, H, W) 作为调试手段，确保张量维度和你设想中一致。<li>除了标记 y 外，尽量少使用一维张量，使用 n*1 的二维张量代替，可以避免一些意想不到的一维张量计算结果。<li>统计代码各部分耗时<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="n">profiler</span><span class="p">.</span><span class="n">profile</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">profile</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="p">...</span>
<span class="k">print</span><span class="p">(</span><span class="n">profile</span><span class="p">)</span>
<span class="c1"># 或者在命令行运行
</span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">bottleneck</span> <span class="n">main</span><span class="p">.</span><span class="n">py</span>
</code></pre></div></div><li>使用TorchSnooper来调试PyTorch代码，程序在执行的时候，就会自动 print 出来每一行的执行结果的 tensor 的形状、数据类型、设备、是否需要梯度的信息。<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pip install torchsnooper
</span><span class="kn">import</span> <span class="nn">torchsnooper</span>
<span class="c1"># 对于函数，使用修饰器
</span><span class="o">@</span><span class="n">torchsnooper</span><span class="p">.</span><span class="n">snoop</span><span class="p">()</span>
<span class="c1"># 如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。
</span><span class="k">with</span> <span class="n">torchsnooper</span><span class="p">.</span><span class="n">snoop</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">原本的代码</span>
</code></pre></div></div><li>模型可解释性，使用captum库</ul><p>原文链接：<a href="https://zhuanlan.zhihu.com/p/104019160">[深度学习框架]PyTorch常用代码段-知乎</a></p><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2017-2020 Patrick Marsceill. Distributed by an <a href="https://github.com/just-the-docs/just-the-docs/tree/main/LICENSE.txt">MIT license.</a> <a href="https://www.netlify.com/">This site is powered by Netlify.</a></p><div class="d-flex mt-2"><p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/ZipGao//tree/main/docs/Python/pytorch/Pytorch 常用代码片段合集.md" id="edit-this-page">Edit this page on GitHub</a></p></div></footer></div></div><div class="search-overlay"></div></div>
